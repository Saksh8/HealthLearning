{"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7547567,"sourceType":"datasetVersion","datasetId":4395695},{"sourceId":6100,"sourceType":"modelInstanceVersion","modelInstanceId":4643}],"dockerImageVersionId":30646,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":2123.85405,"end_time":"2024-02-04T00:06:48.395698","environment_variables":{},"exception":true,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-02-03T23:31:24.541648","version":"2.5.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Importing dependencies\n\nimport os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\nfrom tqdm.notebook import tqdm\n\nimport tensorflow as tf\nfrom tensorflow.keras import *\nfrom tensorflow.keras.optimizers import AdamW\nfrom tensorflow.keras.callbacks import *\nimport keras_cv\n\n\nBATCH_SIZE = 16\nAUTO = tf.data.AUTOTUNE","metadata":{"_kg_hide-output":true,"papermill":{"duration":19.027459,"end_time":"2024-02-03T23:31:46.273022","exception":false,"start_time":"2024-02-03T23:31:27.245563","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <span style=\"color:#e74c3c;\"> </span> Preprocessing","metadata":{"papermill":{"duration":0.005875,"end_time":"2024-02-03T23:31:46.285376","exception":false,"start_time":"2024-02-03T23:31:46.279501","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# a function for converting txt file to list\ndef parse_txt_annot(img_path, txt_path):\n    img = cv2.imread(img_path)\n    w = int(img.shape[0])\n    h = int(img.shape[1])\n\n    file_label = open(txt_path, \"r\")\n    lines = file_label.read().split('\\n')\n    \n    boxes = []\n    classes = []\n    \n    if lines[0] == '':\n        return img_path, classes, boxes\n    else:\n        for i in range(0, int(len(lines))):\n            objbud=lines[i].split(' ')\n            class_ = int(objbud[0])\n        \n            x1 = float(objbud[1])\n            y1 = float(objbud[2])\n            w1 = float(objbud[3])\n            h1 = float(objbud[4])\n        \n            xmin = int((x1*w) - (w1*w)/2.0)\n            ymin = int((y1*h) - (h1*h)/2.0)\n            xmax = int((x1*w) + (w1*w)/2.0)\n            ymax = int((y1*h) + (h1*h)/2.0)\n    \n            boxes.append([xmin ,ymin ,xmax ,ymax])\n            classes.append(class_)\n    \n    return img_path, classes, boxes\n\n\n# a function for creating file paths list \ndef create_paths_list(path):\n    full_path = []\n    images = sorted(os.listdir(path))\n    \n    for i in images:\n        full_path.append(os.path.join(path, i))\n        \n    return full_path\n\n\nclass_ids = ['Acne']\nclass_mapping = {0: 'Acne'}","metadata":{"papermill":{"duration":0.019684,"end_time":"2024-02-03T23:31:46.311103","exception":false,"start_time":"2024-02-03T23:31:46.291419","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# a function for creating a dict format of files\ndef creating_files(img_files_paths, annot_files_paths):\n    \n    img_files = create_paths_list(img_files_paths)\n    annot_files = create_paths_list(annot_files_paths)\n    \n    image_paths = []\n    bbox = []\n    classes = []\n    \n    for i in range(0,len(img_files)):\n        image_path_, classes_, bbox_ = parse_txt_annot(img_files[i], annot_files[i])\n        image_paths.append(image_path_)\n        bbox.append(bbox_)\n        classes.append(classes_)\n        \n    image_paths = tf.ragged.constant(image_paths)\n    bbox = tf.ragged.constant(bbox)\n    classes = tf.ragged.constant(classes)\n    \n    return image_paths, classes, bbox","metadata":{"papermill":{"duration":0.015092,"end_time":"2024-02-03T23:31:46.332136","exception":false,"start_time":"2024-02-03T23:31:46.317044","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# applying functions\ntrain_img_paths, train_classes, train_bboxes = creating_files('/kaggle/input/acne-dataset-in-yolov8-format/data-2/train/images', \n                                                              '/kaggle/input/acne-dataset-in-yolov8-format/data-2/train/labels')\n\nvalid_img_paths, valid_classes, valid_bboxes = creating_files('/kaggle/input/acne-dataset-in-yolov8-format/data-2/valid/images',\n                                                             '/kaggle/input/acne-dataset-in-yolov8-format/data-2/valid/labels')\n\ntest_img_paths, test_classes, test_bboxes = creating_files('/kaggle/input/acne-dataset-in-yolov8-format/data-2/test/images',\n                                                          '/kaggle/input/acne-dataset-in-yolov8-format/data-2/test/labels')","metadata":{"papermill":{"duration":13.457229,"end_time":"2024-02-03T23:31:59.795419","exception":false,"start_time":"2024-02-03T23:31:46.33819","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <span style=\"color:#e74c3c;\"> Creating </span> Datasets","metadata":{"papermill":{"duration":0.005826,"end_time":"2024-02-03T23:31:59.80766","exception":false,"start_time":"2024-02-03T23:31:59.801834","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# reading and resizing images\ndef img_preprocessing(img_path):\n    img = tf.io.read_file(img_path)\n    img = tf.image.decode_jpeg(img, channels = 3)\n    img = tf.cast(img, tf.float32) \n    \n    return img\n\n\nresizing = keras_cv.layers.JitteredResize(\n    target_size=(640, 640),\n    scale_factor=(0.8, 1.25),\n    bounding_box_format=\"xyxy\")\n\n# loading dataset\ndef load_ds(img_paths, classes, bbox):\n    img = img_preprocessing(img_paths)\n\n    bounding_boxes = {\n        \"classes\": tf.cast(classes, dtype=tf.float32),\n        \"boxes\": bbox }\n    \n    return {\"images\": img, \"bounding_boxes\": bounding_boxes}\n\ndef dict_to_tuple(inputs):\n    return inputs[\"images\"], inputs[\"bounding_boxes\"]","metadata":{"papermill":{"duration":0.037818,"end_time":"2024-02-03T23:31:59.851375","exception":false,"start_time":"2024-02-03T23:31:59.813557","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating dataset loaders and tf.datasets\ntrain_loader = tf.data.Dataset.from_tensor_slices((train_img_paths, train_classes, train_bboxes))\ntrain_dataset = (train_loader\n                 .map(load_ds, num_parallel_calls = AUTO)\n                 .shuffle(BATCH_SIZE*10)\n                 .ragged_batch(BATCH_SIZE, drop_remainder = True)\n                 .map(resizing, num_parallel_calls = AUTO)\n                 .map(dict_to_tuple, num_parallel_calls = AUTO)\n                 .prefetch(AUTO))\n\n\nvalid_loader = tf.data.Dataset.from_tensor_slices((valid_img_paths, valid_classes, valid_bboxes))\nvalid_dataset = (valid_loader\n                 .map(load_ds, num_parallel_calls = AUTO)\n                 .ragged_batch(BATCH_SIZE, drop_remainder = True)\n                 .map(resizing, num_parallel_calls = AUTO)\n                 .map(dict_to_tuple, num_parallel_calls = AUTO)\n                 .prefetch(AUTO))\n\n\ntest_loader = tf.data.Dataset.from_tensor_slices((test_img_paths, test_classes, test_bboxes))\ntest_dataset = (test_loader\n                .map(load_ds, num_parallel_calls = AUTO)\n                .ragged_batch(BATCH_SIZE, drop_remainder = True)\n                .map(resizing, num_parallel_calls = AUTO)\n                .map(dict_to_tuple, num_parallel_calls = AUTO)\n                .prefetch(AUTO))","metadata":{"papermill":{"duration":8.623777,"end_time":"2024-02-03T23:32:08.481113","exception":false,"start_time":"2024-02-03T23:31:59.857336","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# a function to visualize samples from a dataset\n\ndef visualize_dataset(inputs, value_range, rows, cols, bounding_box_format):\n    inputs = next(iter(inputs.take(1)))\n    images, bounding_boxes = inputs[0], inputs[1]\n    \n    keras_cv.visualization.plot_bounding_box_gallery(\n        images,\n        value_range=value_range,\n        rows=rows,\n        cols=cols,\n        y_true=bounding_boxes,\n        scale = 6,\n        font_scale = 0.8,\n        line_thickness=2,\n        dpi = 100,\n        bounding_box_format=bounding_box_format,\n        class_mapping=class_mapping,\n        true_color = (192, 57, 43))","metadata":{"papermill":{"duration":0.014839,"end_time":"2024-02-03T23:32:08.503229","exception":false,"start_time":"2024-02-03T23:32:08.48839","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]}]}